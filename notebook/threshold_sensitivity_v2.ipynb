{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bc9c2f",
   "metadata": {},
   "source": [
    "# ThinkBrake: Threshold Sensitivity Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf580f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "METRICS_FILE = Path(\"../metrics_summary.jsonl\")\n",
    "INCLUDE_MODELS = [\n",
    "    \"Qwen/Qwen3-4B-Thinking-2507\",\n",
    "    # \"Qwen/Qwen3-4B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    \"microsoft/phi-4-reasoning\",\n",
    "]\n",
    "# CATEGORY = \"dapo-math\"\n",
    "CATEGORY = \"gsm8k-val\"\n",
    "INCLUDE_THRESHOLDS = [0.1, 0.25, 1.0, 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 1039\n"
     ]
    }
   ],
   "source": [
    "def load_metrics(file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Warning: {file_path} not found.\")\n",
    "        return []\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "all_metrics = load_metrics(METRICS_FILE)\n",
    "print(f\"Total records loaded: {len(all_metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88aeea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_data(model_name, benchmark, all_metrics):\n",
    "\n",
    "    model_metrics = [\n",
    "        r\n",
    "        for r in all_metrics\n",
    "        if (\n",
    "            r.get(\"model\") == model_name\n",
    "            or r.get(\"model\") == model_name.replace(\"/\", \"_\")\n",
    "        )\n",
    "        and r.get(\"benchmark\") == benchmark\n",
    "    ]\n",
    "\n",
    "    all_token_counts = [\n",
    "        r.get(\"avg_token_length\")\n",
    "        for r in model_metrics\n",
    "        if r.get(\"avg_token_length\") is not None\n",
    "        and r.get(\"threshold\") in INCLUDE_THRESHOLDS\n",
    "        or r.get(\"method\") == \"rollout\"\n",
    "    ]\n",
    "\n",
    "    global_min_tokens = min(all_token_counts) if all_token_counts else 0\n",
    "    global_max_tokens = max(all_token_counts) if all_token_counts else 0\n",
    "\n",
    "    baseline_entry = next(\n",
    "        (r for r in model_metrics if r.get(\"method\") == \"rollout\"), None\n",
    "    )\n",
    "    base_tokens = baseline_entry.get(\"avg_token_length\", 0) if baseline_entry else 0\n",
    "\n",
    "    plot_data = []\n",
    "    for r in model_metrics:\n",
    "        if r.get(\"method\") == \"thinkbrake\":\n",
    "            try:\n",
    "                t_val = float(r.get(\"threshold\"))\n",
    "                if not any(abs(t_val - t) < 1e-6 for t in INCLUDE_THRESHOLDS):\n",
    "                    continue\n",
    "\n",
    "                token_reduction = None\n",
    "                if baseline_entry:\n",
    "                    base_tokens = baseline_entry.get(\"avg_token_length\", 0)\n",
    "                    curr_tokens = r.get(\"avg_token_length\", 0)\n",
    "                    if base_tokens > 0:\n",
    "                        token_reduction = (\n",
    "                            (base_tokens - curr_tokens) / base_tokens * 100\n",
    "                        )\n",
    "\n",
    "                accuracy = r.get(\"accuracy\", 0)\n",
    "                avg_tok_len = r.get(\"avg_token_length\", 0)\n",
    "                token_efficiency = 1 - (avg_tok_len - global_min_tokens) / (\n",
    "                    global_max_tokens - global_min_tokens\n",
    "                )\n",
    "\n",
    "                entry = {\n",
    "                    \"threshold\": t_val,\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"majority_accuracy\": r.get(\"majority_accuracy\"),\n",
    "                    \"avg_token_length\": avg_tok_len,\n",
    "                    \"min_token_length\": global_min_tokens,\n",
    "                    \"max_token_length\": global_max_tokens,\n",
    "                    \"token_reduction\": token_reduction,\n",
    "                    \"e3_score\": accuracy * accuracy / avg_tok_len,\n",
    "                    \"token_efficiency\": token_efficiency,\n",
    "                    \"overthinking_score\": (2 * accuracy * token_efficiency)\n",
    "                    / (accuracy + token_efficiency),\n",
    "                }\n",
    "                plot_data.append(entry)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(plot_data)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(\"threshold\")\n",
    "\n",
    "    return df, baseline_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "process_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Qwen/Qwen3-4B-Thinking-2507: 4 ThinkBrake points, Baseline found: True\n",
      "Processed deepseek-ai/DeepSeek-R1-Distill-Qwen-7B: 4 ThinkBrake points, Baseline found: True\n",
      "Processed microsoft/phi-4-reasoning: 4 ThinkBrake points, Baseline found: True\n"
     ]
    }
   ],
   "source": [
    "processed_data = {}\n",
    "for model in INCLUDE_MODELS:\n",
    "    df, baseline = process_model_data(model, CATEGORY, all_metrics)\n",
    "    if not df.empty or baseline:\n",
    "        processed_data[model] = {\"df\": df, \"baseline\": baseline}\n",
    "        print(\n",
    "            f\"Processed {model}: {len(df)} ThinkBrake points, Baseline found: {baseline is not None}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No data found for {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c17dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Tokens</th>\n",
       "      <th>E3 Score</th>\n",
       "      <th>Overthinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen3-4B-Thinking-2507</td>\n",
       "      <td>--</td>\n",
       "      <td>95.40</td>\n",
       "      <td>1461.39</td>\n",
       "      <td>6.23</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen3-4B-Thinking-2507</td>\n",
       "      <td>0.10</td>\n",
       "      <td>94.20</td>\n",
       "      <td>1213.12</td>\n",
       "      <td>7.31</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen3-4B-Thinking-2507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>94.80</td>\n",
       "      <td>1185.24</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen3-4B-Thinking-2507</td>\n",
       "      <td>1.00</td>\n",
       "      <td>94.30</td>\n",
       "      <td>1169.80</td>\n",
       "      <td>7.60</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen3-4B-Thinking-2507</td>\n",
       "      <td>2.50</td>\n",
       "      <td>94.00</td>\n",
       "      <td>1111.01</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Threshold  Accuracy  Avg Tokens  E3 Score  \\\n",
       "0  Qwen3-4B-Thinking-2507        --     95.40     1461.39      6.23   \n",
       "1  Qwen3-4B-Thinking-2507      0.10     94.20     1213.12      7.31   \n",
       "2  Qwen3-4B-Thinking-2507      0.25     94.80     1185.24      7.58   \n",
       "3  Qwen3-4B-Thinking-2507      1.00     94.30     1169.80      7.60   \n",
       "4  Qwen3-4B-Thinking-2507      2.50     94.00     1111.01      7.95   \n",
       "\n",
       "  Overthinking  \n",
       "0           --  \n",
       "1         1.41  \n",
       "2         1.56  \n",
       "3         1.65  \n",
       "4         1.98  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Tokens</th>\n",
       "      <th>E3 Score</th>\n",
       "      <th>Overthinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepSeek-R1-Distill-Qwen-7B</td>\n",
       "      <td>--</td>\n",
       "      <td>93.50</td>\n",
       "      <td>1699.73</td>\n",
       "      <td>5.14</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeepSeek-R1-Distill-Qwen-7B</td>\n",
       "      <td>0.10</td>\n",
       "      <td>92.00</td>\n",
       "      <td>1331.04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeepSeek-R1-Distill-Qwen-7B</td>\n",
       "      <td>0.25</td>\n",
       "      <td>92.50</td>\n",
       "      <td>1303.90</td>\n",
       "      <td>6.56</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepSeek-R1-Distill-Qwen-7B</td>\n",
       "      <td>1.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>1159.68</td>\n",
       "      <td>7.62</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeepSeek-R1-Distill-Qwen-7B</td>\n",
       "      <td>2.50</td>\n",
       "      <td>91.50</td>\n",
       "      <td>1054.55</td>\n",
       "      <td>7.94</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Threshold  Accuracy  Avg Tokens  E3 Score  \\\n",
       "0  DeepSeek-R1-Distill-Qwen-7B        --     93.50     1699.73      5.14   \n",
       "1  DeepSeek-R1-Distill-Qwen-7B      0.10     92.00     1331.04      6.36   \n",
       "2  DeepSeek-R1-Distill-Qwen-7B      0.25     92.50     1303.90      6.56   \n",
       "3  DeepSeek-R1-Distill-Qwen-7B      1.00     94.00     1159.68      7.62   \n",
       "4  DeepSeek-R1-Distill-Qwen-7B      2.50     91.50     1054.55      7.94   \n",
       "\n",
       "  Overthinking  \n",
       "0           --  \n",
       "1         1.14  \n",
       "2         1.22  \n",
       "3         1.66  \n",
       "4         1.98  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Tokens</th>\n",
       "      <th>E3 Score</th>\n",
       "      <th>Overthinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phi-4-reasoning</td>\n",
       "      <td>--</td>\n",
       "      <td>92.00</td>\n",
       "      <td>1305.65</td>\n",
       "      <td>6.48</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phi-4-reasoning</td>\n",
       "      <td>0.10</td>\n",
       "      <td>92.00</td>\n",
       "      <td>1196.16</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phi-4-reasoning</td>\n",
       "      <td>0.25</td>\n",
       "      <td>92.00</td>\n",
       "      <td>1095.12</td>\n",
       "      <td>7.73</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phi-4-reasoning</td>\n",
       "      <td>1.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1022.79</td>\n",
       "      <td>8.10</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phi-4-reasoning</td>\n",
       "      <td>2.50</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1161.12</td>\n",
       "      <td>7.13</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Threshold  Accuracy  Avg Tokens  E3 Score Overthinking\n",
       "0  phi-4-reasoning        --     92.00     1305.65      6.48           --\n",
       "1  phi-4-reasoning      0.10     92.00     1196.16      7.08         0.77\n",
       "2  phi-4-reasoning      0.25     92.00     1095.12      7.73         1.48\n",
       "3  phi-4-reasoning      1.00     91.00     1022.79      8.10         1.98\n",
       "4  phi-4-reasoning      2.50     91.00     1161.12      7.13         1.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model, data in processed_data.items():\n",
    "    df = data[\"df\"]\n",
    "    baseline = data[\"baseline\"]\n",
    "    display_name = model.split(\"/\")[-1]\n",
    "    summary_list = []\n",
    "\n",
    "    if baseline:\n",
    "        g_min = (\n",
    "            df[\"min_token_length\"].iloc[0]\n",
    "            if not df.empty\n",
    "            else baseline.get(\"avg_token_length\", 0)\n",
    "        )\n",
    "        g_max = (\n",
    "            df[\"max_token_length\"].iloc[0]\n",
    "            if not df.empty\n",
    "            else baseline.get(\"avg_token_length\", 0)\n",
    "        )\n",
    "\n",
    "        b_acc = baseline.get(\"accuracy\", 0)\n",
    "        b_len = baseline.get(\"avg_token_length\", 0)\n",
    "        b_eff = 1 - (b_len - g_min) / (g_max - g_min) if (g_max - g_min) > 0 else 1.0\n",
    "\n",
    "        summary_list.append(\n",
    "            {\n",
    "                \"Model\": display_name,\n",
    "                \"Threshold\": \"--\",\n",
    "                \"Accuracy\": b_acc,\n",
    "                \"Avg Tokens\": b_len,\n",
    "                \"E3 Score\": (b_acc**2) / b_len if b_len > 0 else 0,\n",
    "                # \"Efficiency\": b_eff,\n",
    "                \"Overthinking\": \"--\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        summary_list.append(\n",
    "            {\n",
    "                \"Model\": display_name,\n",
    "                \"Threshold\": row[\"threshold\"],\n",
    "                \"Accuracy\": row[\"accuracy\"],\n",
    "                \"Avg Tokens\": row[\"avg_token_length\"],\n",
    "                \"E3 Score\": row[\"e3_score\"],\n",
    "                # \"Efficiency\": row[\"token_efficiency\"],\n",
    "                \"Overthinking\": row[\"overthinking_score\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "    display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinkbrake_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
