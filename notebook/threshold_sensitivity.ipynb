{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "26bc9c2f",
            "metadata": {},
            "source": [
                "# Threshold Sensitivity Analysis\n",
                "\n",
                "This notebook analyzes the effect of the reasoning threshold on the model's performance.\n",
                "It reads from `metrics_summary.jsonl`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf580f7a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "# Set plot style\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "\n",
                "# Constants\n",
                "PROJECT_ROOT = Path(\"../\").resolve()\n",
                "METRICS_FILE = PROJECT_ROOT / \"metrics_summary.jsonl\"\n",
                "\n",
                "MODEL_NAME = \"Qwen_Qwen3-4B-Thinking-2507\"  # Updated model name\n",
                "CATEGORY = \"gsm8k\"  # Updated benchmark name"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_metrics(file_path):\n",
                "    if not file_path.exists():\n",
                "        print(f\"Warning: {file_path} not found.\")\n",
                "        return []\n",
                "    data = []\n",
                "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        for line in f:\n",
                "            if line.strip():\n",
                "                data.append(json.loads(line))\n",
                "    return data\n",
                "\n",
                "all_metrics = load_metrics(METRICS_FILE)\n",
                "print(f\"Total records loaded: {len(all_metrics)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "process_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter data for specific model and category\n",
                "model_metrics = [\n",
                "    r for r in all_metrics \n",
                "    if r.get(\"model\") == MODEL_NAME \n",
                "    and r.get(\"benchmark\") == CATEGORY\n",
                "    and r.get(\"sub_category\") is None  # Only main benchmark data\n",
                "]\n",
                "\n",
                "# Identify baseline (rollout)\n",
                "baseline_entry = next(\n",
                "    (r for r in model_metrics if r.get(\"method\") == \"rollout\"), \n",
                "    None\n",
                ")\n",
                "\n",
                "if baseline_entry:\n",
                "    print(f\"Baseline (Rollout) found: Acc={baseline_entry.get('accuracy', 0):.2f}%, AvgTokens={baseline_entry.get('avg_token_length', 0):.1f}\")\n",
                "else:\n",
                "    print(\"Warning: Baseline (Rollout) not found.\")\n",
                "\n",
                "plot_data = []\n",
                "\n",
                "for r in model_metrics:\n",
                "    if r.get(\"method\") == \"thinkbrake\":\n",
                "        try:\n",
                "            t_val = float(r.get(\"threshold\"))\n",
                "            \n",
                "            # Calculate Token Reduction\n",
                "            token_reduction = None\n",
                "            if baseline_entry:\n",
                "                base_tokens = baseline_entry.get(\"avg_token_length\", 0)\n",
                "                curr_tokens = r.get(\"avg_token_length\", 0)\n",
                "                if base_tokens > 0:\n",
                "                    token_reduction = (base_tokens - curr_tokens) / base_tokens * 100\n",
                "            \n",
                "            entry = {\n",
                "                \"threshold\": t_val,\n",
                "                \"accuracy\": r.get(\"accuracy\", 0),\n",
                "                \"majority_accuracy\": r.get(\"majority_accuracy\"),\n",
                "                \"avg_token_length\": r.get(\"avg_token_length\", 0),\n",
                "                \"token_reduction\": token_reduction,\n",
                "                \"type\": \"ThinkBrake\"\n",
                "            }\n",
                "            \n",
                "            # Add pass@k if available\n",
                "            if \"pass@k\" in r and isinstance(r[\"pass@k\"], dict):\n",
                "                for k, v in r[\"pass@k\"].items():\n",
                "                    entry[f\"pass@{k}\"] = v\n",
                "            \n",
                "            plot_data.append(entry)\n",
                "        except (ValueError, TypeError):\n",
                "            continue\n",
                "\n",
                "df = pd.DataFrame(plot_data)\n",
                "if not df.empty:\n",
                "    df = df.sort_values(\"threshold\")\n",
                "    print(df.head())\n",
                "else:\n",
                "    print(\"No ThinkBrake data available for plotting.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plotting",
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df.empty:\n",
                "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
                "\n",
                "    # Plot Accuracy on primary y-axis\n",
                "    color = 'tab:blue'\n",
                "    ax1.set_xlabel('Threshold')\n",
                "    ax1.set_ylabel('Accuracy (%)', color=color)\n",
                "    line1 = ax1.plot(df['threshold'], df['accuracy'], marker='o', color=color, label='Accuracy')\n",
                "    ax1.tick_params(axis='y', labelcolor=color)\n",
                "    ax1.grid(True)\n",
                "    \n",
                "    # Plot Baseline Accuracy if available\n",
                "    if baseline_entry:\n",
                "        base_acc = baseline_entry.get(\"accuracy\", 0)\n",
                "        line_base = ax1.axhline(y=base_acc, color='gray', linestyle='--', label='Rollout Baseline')\n",
                "\n",
                "    # Create secondary y-axis for Token Reduction\n",
                "    if \"token_reduction\" in df.columns and df[\"token_reduction\"].notna().any():\n",
                "        ax2 = ax1.twinx()\n",
                "        color = 'tab:red'\n",
                "        ax2.set_ylabel('Token Reduction (%)', color=color)\n",
                "        line2 = ax2.plot(df['threshold'], df['token_reduction'], marker='s', color=color, linestyle='-.', label='Token Reduction')\n",
                "        ax2.tick_params(axis='y', labelcolor=color)\n",
                "        ax2.grid(False)\n",
                "    \n",
                "    plt.title(f'Threshold Sensitivity: {MODEL_NAME} on {CATEGORY}')\n",
                "    \n",
                "    # Combine legends\n",
                "    lines = line1\n",
                "    if \"line2\" in locals():\n",
                "        lines += line2\n",
                "    if \"line_base\" in locals():\n",
                "        lines.append(line_base)\n",
                "        \n",
                "    labels = [l.get_label() for l in lines]\n",
                "    ax1.legend(lines, labels, loc='best')\n",
                "    \n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}